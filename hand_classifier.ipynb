{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveen/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# CNN for hand classification\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "K.set_image_dim_ordering('tf')\n",
    "# Fixing random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining convolution neural network\n",
    "def cnn_model():\n",
    "\t# Creating model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (7, 7), input_shape=(200, 200, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(200, 200, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Conv2D(15, (5, 5), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compiling model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2750 images belonging to 3 classes.\n",
      "Found 1621 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Using ImageDataGenerator to augment input data\n",
    "train_datagen = ImageDataGenerator(\n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1,\n",
    "        rotation_range=70,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Creating generators for input and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train2.0',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation2.0',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of keras callbacks\n",
    "callbacks = [ModelCheckpoint('bestmodel.h5', verbose=1, monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 89s 443ms/step - loss: 0.7899 - acc: 0.5962 - val_loss: 0.6795 - val_acc: 0.6755\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67955, saving model to bestmodel.h5\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 82s 408ms/step - loss: 0.6790 - acc: 0.6537 - val_loss: 0.7795 - val_acc: 0.6083\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67955\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 82s 410ms/step - loss: 0.6171 - acc: 0.6916 - val_loss: 0.5536 - val_acc: 0.7329\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67955 to 0.55360, saving model to bestmodel.h5\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 83s 413ms/step - loss: 0.5533 - acc: 0.7517 - val_loss: 0.5535 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55360 to 0.55352, saving model to bestmodel.h5\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 82s 408ms/step - loss: 0.4587 - acc: 0.8110 - val_loss: 0.5699 - val_acc: 0.7711\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.55352\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 84s 422ms/step - loss: 0.4264 - acc: 0.8297 - val_loss: 0.4034 - val_acc: 0.8384\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55352 to 0.40339, saving model to bestmodel.h5\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 87s 436ms/step - loss: 0.3535 - acc: 0.8588 - val_loss: 0.3124 - val_acc: 0.8772\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40339 to 0.31242, saving model to bestmodel.h5\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 84s 418ms/step - loss: 0.3545 - acc: 0.8579 - val_loss: 0.4456 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31242\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 86s 429ms/step - loss: 0.3290 - acc: 0.8716 - val_loss: 0.3870 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31242\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 84s 418ms/step - loss: 0.3236 - acc: 0.8689 - val_loss: 0.3568 - val_acc: 0.8624\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31242\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 87s 433ms/step - loss: 0.3008 - acc: 0.8803 - val_loss: 0.2542 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31242 to 0.25417, saving model to bestmodel.h5\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 88s 438ms/step - loss: 0.2847 - acc: 0.8879 - val_loss: 0.2888 - val_acc: 0.8957\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25417\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 87s 434ms/step - loss: 0.3134 - acc: 0.8729 - val_loss: 0.3119 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25417\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 89s 443ms/step - loss: 0.2716 - acc: 0.8901 - val_loss: 0.3193 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25417\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.2718 - acc: 0.8910 - val_loss: 0.2960 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25417\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 91s 454ms/step - loss: 0.2389 - acc: 0.9060 - val_loss: 0.2396 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25417 to 0.23955, saving model to bestmodel.h5\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 85s 423ms/step - loss: 0.2391 - acc: 0.9015 - val_loss: 0.2270 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23955 to 0.22696, saving model to bestmodel.h5\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 83s 415ms/step - loss: 0.2408 - acc: 0.9026 - val_loss: 0.2523 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.22696\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 86s 429ms/step - loss: 0.2023 - acc: 0.9188 - val_loss: 0.1979 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22696 to 0.19794, saving model to bestmodel.h5\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 84s 422ms/step - loss: 0.2077 - acc: 0.9170 - val_loss: 0.3351 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.19794\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 84s 419ms/step - loss: 0.2011 - acc: 0.9248 - val_loss: 0.2041 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.19794\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 85s 426ms/step - loss: 0.1695 - acc: 0.9318 - val_loss: 0.1986 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.19794\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 89s 447ms/step - loss: 0.1898 - acc: 0.9248 - val_loss: 0.2110 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.19794\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 86s 431ms/step - loss: 0.1753 - acc: 0.9333 - val_loss: 0.2151 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19794\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.1925 - acc: 0.9268 - val_loss: 0.2035 - val_acc: 0.9303\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.19794\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 84s 420ms/step - loss: 0.1707 - acc: 0.9348 - val_loss: 0.2568 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.19794\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 85s 427ms/step - loss: 0.1587 - acc: 0.9394 - val_loss: 0.2134 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.19794\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 84s 421ms/step - loss: 0.1391 - acc: 0.9446 - val_loss: 0.1901 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19794 to 0.19007, saving model to bestmodel.h5\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 86s 429ms/step - loss: 0.1698 - acc: 0.9335 - val_loss: 0.1938 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.19007\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 87s 434ms/step - loss: 0.1522 - acc: 0.9409 - val_loss: 0.2012 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.19007\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 84s 419ms/step - loss: 0.1382 - acc: 0.9451 - val_loss: 0.2251 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.19007\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 85s 424ms/step - loss: 0.1647 - acc: 0.9382 - val_loss: 0.2617 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.19007\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 85s 426ms/step - loss: 0.1394 - acc: 0.9470 - val_loss: 0.1899 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19007 to 0.18988, saving model to bestmodel.h5\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 83s 416ms/step - loss: 0.1386 - acc: 0.9470 - val_loss: 0.2301 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.18988\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 84s 420ms/step - loss: 0.1420 - acc: 0.9483 - val_loss: 0.1615 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18988 to 0.16154, saving model to bestmodel.h5\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 87s 433ms/step - loss: 0.1236 - acc: 0.9547 - val_loss: 0.1775 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16154\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 84s 418ms/step - loss: 0.1116 - acc: 0.9607 - val_loss: 0.1748 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16154\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 82s 408ms/step - loss: 0.1587 - acc: 0.9400 - val_loss: 0.2283 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16154\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 86s 431ms/step - loss: 0.1194 - acc: 0.9554 - val_loss: 0.1562 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16154 to 0.15624, saving model to bestmodel.h5\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 83s 413ms/step - loss: 0.1320 - acc: 0.9493 - val_loss: 0.1718 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.15624\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 82s 408ms/step - loss: 0.1486 - acc: 0.9478 - val_loss: 0.1599 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.15624\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 82s 410ms/step - loss: 0.1142 - acc: 0.9557 - val_loss: 0.1870 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.15624\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 83s 415ms/step - loss: 0.1178 - acc: 0.9562 - val_loss: 0.1508 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15624 to 0.15084, saving model to bestmodel.h5\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 84s 418ms/step - loss: 0.1038 - acc: 0.9616 - val_loss: 0.1473 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.15084 to 0.14733, saving model to bestmodel.h5\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 83s 416ms/step - loss: 0.1280 - acc: 0.9504 - val_loss: 0.1761 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.14733\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 83s 416ms/step - loss: 0.0944 - acc: 0.9673 - val_loss: 0.1466 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14733 to 0.14664, saving model to bestmodel.h5\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 96s 478ms/step - loss: 0.0986 - acc: 0.9627 - val_loss: 0.1824 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.14664\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 84s 420ms/step - loss: 0.1106 - acc: 0.9603 - val_loss: 0.4076 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.14664\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.1119 - acc: 0.9602 - val_loss: 0.2029 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.14664\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 88s 439ms/step - loss: 0.1103 - acc: 0.9611 - val_loss: 0.1838 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.14664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f598e42fcc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model\n",
    "model = cnn_model()\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch = 200,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
